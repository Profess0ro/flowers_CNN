{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modelling and evaluation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "- **Answering business requirement 2:**\n",
    "    * The client wants us to develop a machine learning model that can predict with an accuracy higher than 80%.\n",
    "\n",
    "### Inputs\n",
    "\n",
    "- inputs/dataset/raw/flower_photos/train<br>\n",
    "- inputs/dataset/raw/flower_photos/validation<br>\n",
    "- inputs/dataset/raw/flower_photos/test<br>\n",
    "\n",
    "### Outputs\n",
    "\n",
    "- Image augmentation<br>\n",
    "- Machine learning model creation and training the model<br>\n",
    "- Plot showing learning curve for model performance<br>\n",
    "- Model evaluation as a JSON-file<br>\n",
    "- Confusion matrix as a heatmap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Install Requirements and Prepare Workspace**\n",
    "\n",
    "### Workspace setup\n",
    "\n",
    "First let see that we are working from the correct directory that should be \"flowers_CNN\".<br>\n",
    "By default the working directory is \"..../flowers_CNN/jupyter_notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "working_dir = os.getcwd()\n",
    "print(f\"You are now working in {working_dir}\")\n",
    "print(\"If you need to change to the parent directory, run the cell below\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(working_dir))\n",
    "new_working_dir = os.getcwd()\n",
    "print(f\"You have now changed your working directory to {new_working_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set output destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'v8'\n",
    "file_path = f'outputs/{version}'\n",
    "current_working_dir = os.getcwd()\n",
    "\n",
    "if 'outputs' in os.listdir(current_working_dir) and version in os.listdir(current_working_dir + '/outputs'):\n",
    "    print(\"This version already exists, create a new version if you are working on a new version\")\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(name=file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set folder paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dirs = 'inputs/dataset/raw/flower_photos'\n",
    "train_path = image_dirs + '/train'\n",
    "val_path = image_dirs + '/validation'\n",
    "test_path = image_dirs + '/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationPipeline:\n",
    "    \"\"\"\n",
    "    A class to handle the complete pipeline for training, evaluating, and visualizing an image classification model.\n",
    "    \n",
    "    This class provides methods to:\n",
    "    1. Initialize data generators for training, validation, and test sets from directory-based image data.\n",
    "    2. Build a Convolutional Neural Network (CNN) model for classification tasks.\n",
    "    3. Train the model with data augmentation and early stopping to avoid overfitting.\n",
    "    4. Evaluate the model using classification metrics such as F1-score, classification report, and confusion matrix.\n",
    "    5. Visualize training history with accuracy and loss curves.\n",
    "    6. Save the model and evaluation results to specified paths.\n",
    "\n",
    "    Attributes:\n",
    "    - train_path: str, the path to the training data directory.\n",
    "    - val_path: str, the path to the validation data directory.\n",
    "    - test_path: str, the path to the test data directory.\n",
    "    - input_shape: tuple, the shape of input images (default is (224, 224, 3)).\n",
    "    - batch_size: int, the batch size for training (default is 20).\n",
    "    - num_classes: int, the number of output classes (default is 5).\n",
    "    - train_set: DirectoryIterator, generator for the training data.\n",
    "    - validation_set: DirectoryIterator, generator for the validation data.\n",
    "    - test_set: DirectoryIterator, generator for the test data.\n",
    "    - model: keras Model, the CNN model used for classification.\n",
    "    - history: History, the training history object that stores training/validation metrics.\n",
    "\n",
    "    Methods:\n",
    "    - __init__: Initializes the pipeline with directories, image shape, batch size, and number of classes.\n",
    "    - build_model: Builds a CNN model using Conv2D, MaxPooling2D, Dense, Dropout layers, and softmax output layer.\n",
    "    - train: Trains the model with data augmentation and early stopping.\n",
    "    - evaluate: Evaluates the model on the test set and prints metrics like F1-score, classification report, and confusion matrix.\n",
    "    - plot_training_history: Plots and saves the training/validation accuracy and loss over epochs.\n",
    "    - save_model: Saves the trained model to a specified file path.\n",
    "    - model_summary: Displays a summary of the model architecture.\n",
    "    \"\"\"\n",
    "    def __init__(self, train_path, val_path, test_path, input_shape=(224, 224, 3), batch_size=20, num_classes=5):\n",
    "        \"\"\"\n",
    "        Initialize the ImageClassificationPipeline object with paths for training, validation, \n",
    "        and test datasets, as well as other parameters for model setup.\n",
    "        \n",
    "        Parameters:\n",
    "        - train_path: str, path to the training dataset.\n",
    "        - val_path: str, path to the validation dataset.\n",
    "        - test_path: str, path to the test dataset.\n",
    "        - input_shape: tuple, shape of input images (default is (224, 224, 3)).\n",
    "        - batch_size: int, batch size for data generators (default is 20).\n",
    "        - num_classes: int, number of output classes (default is 5).\n",
    "        \"\"\"\n",
    "        self.train_path = train_path\n",
    "        self.val_path = val_path\n",
    "        self.test_path = test_path\n",
    "        self.input_shape = input_shape\n",
    "        self.batch_size = batch_size\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Initialize ImageDataGenerators with data augmentation for training and rescaling for validation/test\n",
    "        self.train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255, # Normalize pixel values\n",
    "            rotation_range=20, # Random rotation within a range\n",
    "            width_shift_range=0.10, # Random horizontal shift\n",
    "            height_shift_range=0.10, # Random vertical shift\n",
    "            shear_range=0.1, # Random shearing transformation\n",
    "            zoom_range=0.1, # Random zoom\n",
    "            horizontal_flip=True, # Random horizontal flip\n",
    "            vertical_flip=True, # Random vertical flip\n",
    "            fill_mode='nearest' # Fill missing pixels after transformations\n",
    "        )\n",
    "        self.val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "        # Build data generators using the specified dataset paths\n",
    "        self.train_set = self.train_datagen.flow_from_directory(\n",
    "            self.train_path, target_size=self.input_shape[:2], batch_size=self.batch_size,\n",
    "            class_mode='categorical', shuffle=True\n",
    "        )\n",
    "        self.validation_set = self.val_test_datagen.flow_from_directory(\n",
    "            self.val_path, target_size=self.input_shape[:2], batch_size=self.batch_size,\n",
    "            class_mode='categorical', shuffle=False\n",
    "        )\n",
    "        self.test_set = self.val_test_datagen.flow_from_directory(\n",
    "            self.test_path, target_size=self.input_shape[:2], batch_size=self.batch_size,\n",
    "            class_mode='categorical', shuffle=False\n",
    "        )\n",
    "        # Print class labels to map indices\n",
    "        print(\"Class indices:\", self.train_set.class_indices)\n",
    "        \n",
    "        # Retrieve label map from the training set\n",
    "        self.label_map = list(self.train_set.class_indices.keys())\n",
    "        \n",
    "        # Build the CNN model\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        Constructs a CNN model for image classification.\n",
    "        \n",
    "        The model consists of three convolutional layers followed by fully connected layers, \n",
    "        and uses dropout for regularization.\n",
    "        \n",
    "        Returns:\n",
    "        - model: A compiled Keras Sequential model ready for training.\n",
    "        \"\"\"\n",
    "        model = Sequential([\n",
    "            # First convolutional layer\n",
    "            Conv2D(16, (3, 3), activation='relu', input_shape=self.input_shape),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            \n",
    "            # Second convolutional layer\n",
    "            Conv2D(32, (3, 3), activation='relu'),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            \n",
    "            # Third convolutional layer\n",
    "            Conv2D(64, (3, 3), activation='relu'),\n",
    "            MaxPooling2D(pool_size=(2, 2)),            \n",
    "            \n",
    "            Flatten(), # Flatten the output of the convolutional layers\n",
    "            Dense(64, activation='relu'), # Fully connected layer\n",
    "            Dropout(0.5), # Dropout layer for regularization\n",
    "            Dense(self.num_classes, activation='softmax') # Output layer with softmax activation\n",
    "        ])\n",
    "        \n",
    "        # Compile the model using Adam optimizer and categorical crossentropy loss function\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def train(self, epochs=25, early_stopping_patience=3):\n",
    "        \"\"\"\n",
    "        Train the model on the training dataset with early stopping based on validation loss.\n",
    "        \n",
    "        Parameters:\n",
    "        - epochs: int, the number of epochs to train (default is 25).\n",
    "        - early_stopping_patience: int, number of epochs to wait for improvement before stopping (default is 3).\n",
    "        \"\"\"\n",
    "        # Early stopping callback to prevent overfitting\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=early_stopping_patience, restore_best_weights=True)\n",
    "        \n",
    "        # Train the model and store the training history\n",
    "        self.history = self.model.fit(\n",
    "            self.train_set,\n",
    "            validation_data=self.validation_set,\n",
    "            epochs=epochs,\n",
    "            callbacks=[early_stop],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "    def evaluate(self, savepath=None,  cm_image_path=None): \n",
    "        \"\"\"\n",
    "        Evaluate the model on the test dataset and print metrics like F1 score, classification report, \n",
    "        and confusion matrix.\n",
    "        \n",
    "        Optionally, save the evaluation results and confusion matrix to files.\n",
    "        \n",
    "        Parameters:\n",
    "        - savepath: str, path to save evaluation data as a JSON file (optional).\n",
    "        - cm_image_path: str, path to save the confusion matrix image (optional).\n",
    "        \"\"\"\n",
    "        y_pred_probs = self.model.predict(self.test_set)\n",
    "        y_pred = np.argmax(y_pred_probs, axis=1) # Convert probabilities to class predictions\n",
    "        y_true = self.test_set.classes # True labels from the test set\n",
    "\n",
    "        # Calculate F1 score\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "        print(f\"F1 Score (weighted): {f1:.4f}\")\n",
    "\n",
    "        # Classification report\n",
    "        report = classification_report(y_true, y_pred, target_names=self.label_map, output_dict=True)\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(report)\n",
    "\n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=self.label_map)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.show()\n",
    "\n",
    "        if cm_image_path:\n",
    "            disp.plot(cmap=plt.cm.Blues)\n",
    "            plt.savefig(cm_image_path, bbox_inches='tight', dpi=150)\n",
    "            print(f\"Confusion matrix image saved as {cm_image_path}\")\n",
    "        \n",
    "        # Save evaluation data to JSON file if savepath is provided\n",
    "        if savepath:\n",
    "            evaluation_data = {\n",
    "                \"f1_score_weighted\": f1,\n",
    "                \"classification_report\": report,\n",
    "                \"confusion_matrix\": cm.tolist()  # Converts numpy array to list for JSON-file\n",
    "            }\n",
    "            \n",
    "            with open(savepath, 'w') as f:\n",
    "                json.dump(evaluation_data, f, indent=4)\n",
    "            print(f\"Evaluation saved as {savepath}\")\n",
    "\n",
    "    def plot_training_history(self, savepath):\n",
    "        \"\"\"\n",
    "        Plot and save training history for accuracy and loss over epochs.\n",
    "        \n",
    "        Parameters:\n",
    "        - savepath: str, path to save the training history plot.\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        # Accuracy plot\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(self.history.history['accuracy'], label='Train Accuracy')\n",
    "        plt.plot(self.history.history['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Training and Validation Accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "        # Loss plot\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(self.history.history['loss'], label='Train Loss')\n",
    "        plt.plot(self.history.history['val_loss'], label='Validation Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(savepath, bbox_inches='tight', dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def save_model(self, filepath):\n",
    "        \"\"\"\n",
    "        Save the trained model to a file.\n",
    "        \n",
    "        Parameters:\n",
    "        - filepath: str, path to save the model.\n",
    "        \"\"\"\n",
    "        self.model.save(filepath)\n",
    "        print(f\"Model saved as {filepath}\")\n",
    "        \n",
    "    def model_summary(self):\n",
    "        \"\"\"\n",
    "        Print the summary of the model architecture.\n",
    "        \"\"\"\n",
    "        self.model.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ImageClassificationPipeline(train_path, val_path, test_path)\n",
    "pipeline.train(epochs=25)\n",
    "pipeline.save_model(f\"{file_path}/flower_prediction_model.h5\") # Savepath for model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Savepaths for the model evaluation and confusion matrix\n",
    "pipeline.evaluate(savepath=f\"{file_path}/model_evaluation.json\", cm_image_path=f\"{file_path}/confusion_matrix.png\")\n",
    "pipeline.model_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.plot_training_history(savepath=f\"{file_path}/training_history.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_display_evaluation_results(file_path):\n",
    "    \"\"\"\n",
    "    Loads and displays the evaluation results from a JSON file, including the weighted F1 score, \n",
    "    classification report, and confusion matrix. The classification report is formatted into a \n",
    "    readable DataFrame, and the confusion matrix is displayed as a DataFrame with labels.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: str, path to the directory containing the 'model_evaluation.json' file.\n",
    "\n",
    "    Outputs:\n",
    "    - Prints the weighted F1 score.\n",
    "    - Prints the formatted classification report as a DataFrame.\n",
    "    - Prints the confusion matrix as a DataFrame.\n",
    "    \"\"\"\n",
    "    json_file = f\"{file_path}/model_evaluation.json\"\n",
    "\n",
    "    # Load evaluation data from the JSON file\n",
    "    with open(json_file, 'r') as f:\n",
    "        evaluation_data = json.load(f)\n",
    "    \n",
    "    # Print the weighted F1 score\n",
    "    print(f\"Weighted F1 Score: {evaluation_data['f1_score_weighted']:.4}\\n\")\n",
    "\n",
    "\n",
    "    # Transforms the classification report into a more readable DataFrame format\n",
    "    classification_report_df = pd.DataFrame(evaluation_data['classification_report']).transpose()\n",
    "    classification_report_df = classification_report_df.round(4)\n",
    "\n",
    "    # Add a blank row for readability and rearrange the rows\n",
    "    classification_report_df = pd.concat([\n",
    "        classification_report_df.iloc[:-3],  \n",
    "        pd.DataFrame([[''] * len(classification_report_df.columns)], columns=classification_report_df.columns),  \n",
    "        classification_report_df.iloc[-3:]  \n",
    "    ]).reset_index()\n",
    "\n",
    "    classification_report_df.index.name = None\n",
    "\n",
    "    # Set display options for better formatting\n",
    "    pd.set_option('display.colheader_justify', 'center')\n",
    "    pd.set_option('display.width', 100)\n",
    "\n",
    "    # Print the classification report\n",
    "    print(\"Classification Report:\\n\", classification_report_df.to_string(index=False))\n",
    "\n",
    "    # Create and print the confusion matrix as a DataFrame\n",
    "    labels = list(evaluation_data['classification_report'].keys())[:-3] # Excludes the last 3 labels\n",
    "    confussion_matrix_df = pd.DataFrame(\n",
    "        evaluation_data['confusion_matrix'],\n",
    "        index = labels,\n",
    "        columns = labels\n",
    "    )\n",
    "\n",
    "    print(\"\\nConfussion Matrix:\\n\", confussion_matrix_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show evaluation of the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_and_display_evaluation_results(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of a random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_random_image(model, label_map, img_path, target_size=(224, 224)):\n",
    "    \n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  \n",
    "    img_array /= 255.0  \n",
    "\n",
    "    # Makes a prediction of a random image\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "    predicted_label = label_map[predicted_class]\n",
    "    confidence = predictions[0][predicted_class] * 100\n",
    "\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Prediction: {predicted_label} ({confidence:.2f}% confidence)\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "test_dir = \"inputs/dataset/raw/flower_photos/test\"  \n",
    "random_class = random.choice(os.listdir(test_dir))  # Choose a random image\n",
    "random_img_path = os.path.join(test_dir, random_class, random.choice(os.listdir(os.path.join(test_dir, random_class))))\n",
    "\n",
    "# Prediction of an image\n",
    "predict_random_image(pipeline.model, pipeline.label_map, random_img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Results of all versions tested\n",
    "\n",
    "\n",
    "| Version | Balanced / Unbalanced | Layers           | Kernels       | Total params   | Runtime | Accuracy | F1-Score | Comments                                                        |\n",
    "| ------- | --------------------- | ---------------- | -------------  | -------------- | ------- | -------- | -------- | --------------------------------------------------------------- |\n",
    "| 1       | Unbalanced            | 32 - 64 - 128    | 3x3, 3x3, 3x3 | 33,508,817     | 209 min | 0.8329   | 0.8336   | Good result, though very large model file. Going to half the layers and see if the result will be the same and lesser size of the .h5-file |\n",
    "| 2       | Unbalanced            | 16 - 32 - 64     | 3x3, 3x3, 3x3 | 8,378,609      | 124 min | 0.8258   | 0.8244   | Good result, almost the same result when decreasing the layers to the half of the first version. The model now are around 33Mb instead of over 130Mb with the first model |\n",
    "| 3       | Unbalanced            | 16 - 32 - 64     | 5x5, 5x5, 5x5 | 7,274,993      | 156 min | 0.8167   | 0.8183   | Good result, almost identical even when increasing the kernel size. Still the largest confusion is between tulips and roses |\n",
    "| 4       | Unbalanced            | 16 - 32 - 64     | 5x5, 5x5, 5x5 | 223,729      | 55 min | 0.7087   | 0.6998   | Tried GlobalAveragePooling2D instead of Flatten on this layer and it didn´t go so well. Changing back to Flatten for the next version and increasing the layers. |\n",
    "| 5       | Unbalanced            | 32 - 64 - 64     | 5x5, 5x5, 5x5 | 14,627,857      | 347 min | 0.7021   | 0.6819   | Adjust the augmentation with this model and the performance decreased instead. Will try next time with a balanced version 2. See if the performance of that can increase |\n",
    "| 6       | Balanced (Undersampled)           | 16 - 32 - 64     | 3x3, 3x3, 3x3 | 8,379,505      | 68 min | 0.3536   | 0.2851   | Poor result when undersampled the categories. Settings where the same as the best performance at version 2. Ran with BatchNormalization() that made a poor result |\n",
    "| 7       | Balanced (Oversampled)           | 16 - 32 - 64     | 3x3, 3x3, 3x3 | 8,378,609      | 129 min | 0.8193   | 0.8189   | Deleted BatchNormalization in every layer and got a result very similar to version 2. Seems like oversampling didn´t do that much to the performance. |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
