{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are now working in c:\\Users\\fredd\\Desktop\\Studier\\Project5\\flowers\\flowers_CNN\n",
      "If you need to change to the parent directory, run the cell below\n"
     ]
    }
   ],
   "source": [
    "working_dir = os.getcwd()\n",
    "print(f\"You are now working in {working_dir}\")\n",
    "print(\"If you need to change to the parent directory, run the cell below\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(working_dir))\n",
    "new_working_dir = os.getcwd()\n",
    "print(f\"You have now changed your working directory to {new_working_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version already exists, create a new version if you are working on a new version\n"
     ]
    }
   ],
   "source": [
    "version = 'v5'\n",
    "file_path = f'outputs/{version}'\n",
    "current_working_dir = os.getcwd()\n",
    "\n",
    "if 'outputs' in os.listdir(current_working_dir) and version in os.listdir(current_working_dir + '/outputs'):\n",
    "    print(\"This version already exists, create a new version if you are working on a new version\")\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(name=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dirs = 'inputs/dataset/raw/flower_photos'\n",
    "train_path = image_dirs + '/train'\n",
    "val_path = image_dirs + '/validation'\n",
    "test_path = image_dirs + '/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flower labels: ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n"
     ]
    }
   ],
   "source": [
    "labels = os.listdir(train_path)\n",
    "print(f\"Flower labels: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ImageClassificationPipeline:\n",
    "    def __init__(self, train_path, val_path, test_path, input_shape=(224, 224, 3), batch_size=20, num_classes=5):\n",
    "        self.train_path = train_path\n",
    "        self.val_path = val_path\n",
    "        self.test_path = test_path\n",
    "        self.input_shape = input_shape\n",
    "        self.batch_size = batch_size\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Initialize ImageDataGenerators\n",
    "        self.train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=30,\n",
    "            width_shift_range=0.10,\n",
    "            height_shift_range=0.10,\n",
    "            shear_range=0.1,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=False,\n",
    "            fill_mode='nearest',\n",
    "            brightness_range=[0.8, 1.2],\n",
    "            channel_shift_range=0.1\n",
    "        )\n",
    "        self.val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "        # Build data generators\n",
    "        self.train_set = self.train_datagen.flow_from_directory(\n",
    "            self.train_path, target_size=self.input_shape[:2], batch_size=self.batch_size,\n",
    "            class_mode='categorical', shuffle=True\n",
    "        )\n",
    "        self.validation_set = self.val_test_datagen.flow_from_directory(\n",
    "            self.val_path, target_size=self.input_shape[:2], batch_size=self.batch_size,\n",
    "            class_mode='categorical', shuffle=False\n",
    "        )\n",
    "        self.test_set = self.val_test_datagen.flow_from_directory(\n",
    "            self.test_path, target_size=self.input_shape[:2], batch_size=self.batch_size,\n",
    "            class_mode='categorical', shuffle=False\n",
    "        )\n",
    "        \n",
    "        # Retrieve label map\n",
    "        self.label_map = list(self.train_set.class_indices.keys())\n",
    "        \n",
    "        # Build model\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        model = Sequential([\n",
    "            Conv2D(16, (5, 5), activation='relu', input_shape=self.input_shape),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            \n",
    "            Conv2D(32, (5, 5), activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            \n",
    "            Conv2D(64, (5, 5), activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D(pool_size=(2, 2)),            \n",
    "            \n",
    "            Flatten(),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(self.num_classes, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def train(self, epochs=25, early_stopping_patience=3):\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=early_stopping_patience, restore_best_weights=True)\n",
    "        \n",
    "        self.history = self.model.fit(\n",
    "            self.train_set,\n",
    "            validation_data=self.validation_set,\n",
    "            epochs=epochs,\n",
    "            callbacks=[early_stop],\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "    def evaluate(self, savepath=None,  cm_image_path=None): \n",
    "        y_pred_probs = self.model.predict(self.test_set)\n",
    "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "        y_true = self.test_set.classes\n",
    "\n",
    "        # Calculate F1 score\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "        print(f\"F1 Score (weighted): {f1:.4f}\")\n",
    "\n",
    "        # Classification report\n",
    "        report = classification_report(y_true, y_pred, target_names=self.label_map, output_dict=True)\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(report)\n",
    "\n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=self.label_map)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.show()\n",
    "\n",
    "        if cm_image_path:\n",
    "            disp.plot(cmap=plt.cm.Blues)\n",
    "            plt.savefig(cm_image_path, bbox_inches='tight', dpi=150)\n",
    "            print(f\"Confusion matrix image saved as {cm_image_path}\")\n",
    "        \n",
    "        # If savepath is given, save JSON-file\n",
    "        if savepath:\n",
    "            evaluation_data = {\n",
    "                \"f1_score_weighted\": f1,\n",
    "                \"classification_report\": report,\n",
    "                \"confusion_matrix\": cm.tolist()  # Converts numpy array to list for JSON-file\n",
    "            }\n",
    "\n",
    "            # Saves data as JSON-file\n",
    "            with open(savepath, 'w') as f:\n",
    "                json.dump(evaluation_data, f, indent=4)\n",
    "            print(f\"Evaluation saved as {savepath}\")\n",
    "\n",
    "    def plot_training_history(self, savepath):\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        # Accuracy plot\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(self.history.history['accuracy'], label='Train Accuracy')\n",
    "        plt.plot(self.history.history['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Training and Validation Accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "        # Loss plot\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(self.history.history['loss'], label='Train Loss')\n",
    "        plt.plot(self.history.history['val_loss'], label='Validation Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(savepath, bbox_inches='tight', dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def save_model(self, filepath):\n",
    "        self.model.save(filepath)\n",
    "        print(f\"Model saved as {filepath}\")\n",
    "        \n",
    "    def model_summary(self):\n",
    "        self.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ImageClassificationPipeline(train_path, val_path, test_path)\n",
    "pipeline.train(epochs=25)\n",
    "pipeline.save_model(f\"{file_path}/flower_prediction_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.evaluate(savepath=f\"{file_path}/model_evaluation.json\", cm_image_path=f\"{file_path}/confusion_matrix.png\")\n",
    "pipeline.model_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.plot_training_history(savepath=f\"{file_path}/training_history.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = f\"{file_path}/model_evaluation.json\"\n",
    "\n",
    "with open(json_file, 'r') as f:\n",
    "    evaluation_data = json.load(f)\n",
    "    \n",
    "print(f\"Weighted F1 Score: {evaluation_data['f1_score_weighted']:.4}\\n\")\n",
    "\n",
    "\n",
    "# Transforms the JSON-file to a more readable DataFrame\n",
    "classification_report_df = pd.DataFrame(evaluation_data['classification_report']).transpose()\n",
    "classification_report_df = classification_report_df.round(4)\n",
    "\n",
    "classification_report_df = pd.concat([\n",
    "    classification_report_df.iloc[:-3],  \n",
    "    pd.DataFrame([[''] * len(classification_report_df.columns)], columns=classification_report_df.columns),  \n",
    "    classification_report_df.iloc[-3:]  \n",
    "]).reset_index()\n",
    "\n",
    "classification_report_df.index.name = None\n",
    "\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "pd.set_option('display.width', 100)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report_df.to_string(index=False))\n",
    "\n",
    "# Creates a DataFrame for the confussion matrix\n",
    "labels = list(evaluation_data['classification_report'].keys())[:-3] # Excludes the last 3 labels\n",
    "confussion_matrix_df = pd.DataFrame(\n",
    "    evaluation_data['confusion_matrix'],\n",
    "    index = labels,\n",
    "    columns = labels\n",
    ")\n",
    "\n",
    "print(\"\\nConfussion Matrix:\\n\", confussion_matrix_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_random_image(model, label_map, img_path, target_size=(224, 224)):\n",
    "    \n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  \n",
    "    img_array /= 255.0  \n",
    "\n",
    "    # Makes a prediction of a random image\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "    predicted_label = label_map[predicted_class]\n",
    "    confidence = predictions[0][predicted_class] * 100\n",
    "\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Prediction: {predicted_label} ({confidence:.2f}% confidence)\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "test_dir = \"inputs/dataset/raw/flower_photos/test\"  \n",
    "random_class = random.choice(os.listdir(test_dir))  # Choose a random image\n",
    "random_img_path = os.path.join(test_dir, random_class, random.choice(os.listdir(os.path.join(test_dir, random_class))))\n",
    "\n",
    "# Prediction of an image\n",
    "predict_random_image(pipeline.model, pipeline.label_map, random_img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Results\n",
    "\n",
    "\n",
    "| Version | Balanced / Unbalanced | Layers           | Kernels       | Total params   | Runtime | Accuracy | F1-Score | Comments                                                        |\n",
    "| ------- | --------------------- | ---------------- | -------------  | -------------- | ------- | -------- | -------- | --------------------------------------------------------------- |\n",
    "| 1       | Unbalanced            | 32 - 64 - 128    | 3x3, 3x3, 3x3 | 33,508,817     | 209 min | 0.8329   | 0.8336   | Good result, though very large model file. Going to half the layers and see if the result will be the same and lesser size of the .h5-file |\n",
    "| 2       | Unbalanced            | 16 - 32 - 64     | 3x3, 3x3, 3x3 | 8,378,609      | 124 min | 0.8258   | 0.8244   | Good result, almost the same result when decreasing the layers to the half of the first version. The model now are around 33Mb instead of over 130Mb with the first model |\n",
    "| 3       | Unbalanced            | 16 - 32 - 64     | 5x5, 5x5, 5x5 | 7,274,993      | 156 min | 0.8167   | 0.8183   | Good result, almost identical even when increasing the kernel size. Still the largest confusion is between tulips and roses |\n",
    "| 4       | Unbalanced            | 16 - 32 - 64     | 5x5, 5x5, 5x5 | 223,729      | 55 min | 0.7087   | 0.6998   | Tried GlobalAveragePooling2D instead of Flatten on this layer and it didn´t go so well. Changing back to Flatten for the next version and increasing the layers. |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
